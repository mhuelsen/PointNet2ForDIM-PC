{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f0e2a30-0c6c-4eca-858d-16700d7570c0",
   "metadata": {},
   "source": [
    "# Testing PointNet++\n",
    "This Notebook is set up to test some functions and models to build a PointNet++.\n",
    "\n",
    "The main functions are from <a href='https://github.com/yanx27/Pointnet_Pointnet2_pytorch/tree/master'>Xu Yan - GitHub</a>\n",
    "\n",
    "<b>This Jupyter-Notebook is part of a master thesis with the topic<br>\n",
    "<i>Analysis of deep learning methods for semantic segmentation of photogrammetric point clouds from aerial images</i><br>\n",
    "&copy; Markus HÃ¼lsen, Matr.-Nr. 6026370<br>\n",
    "Date: 15.08.2023</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb6a1d4-437d-4e76-b1d3-2424f74c4738",
   "metadata": {},
   "source": [
    "## Libarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26968f82-c43d-4710-9eec-f923518b21cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import laspy\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d25f24-04e9-430b-b67a-df58b92b4872",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Data\n",
    "Data is stored as `LAS`-file. We will use `laspy` to import und convert the data.<br>\n",
    "First we create a function to import an `LAS`-File and convert them into a Pandas `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1bbe0fc-277a-417d-8105-a0b13199c58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_las_to_Dataframe(path):\n",
    "    with laspy.open(path) as f:\n",
    "        las = f.read()\n",
    "    \n",
    "    # read coordinates from las\n",
    "    x = np.array(las.x)\n",
    "    y = np.array(las.y)\n",
    "    z = np.array(las.z)\n",
    "\n",
    "    df = pd.DataFrame({'X':x,'Y':y,'Z':z},index=np.arange(len(x)))\n",
    "\n",
    "    for i in range(3, len(las.point_format.dimensions)):\n",
    "        dim = las.point_format.dimensions[i].name\n",
    "        df[dim] = np.array(las[dim])\n",
    "     \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f3edfe-2986-4466-8634-6eeeef598151",
   "metadata": {},
   "source": [
    "Express path where the data is stored, that we want to processed. <br>All `las`-Files inside the defined folder will be stored in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c336673-0b11-4f93-8d70-d7d87826f0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 laz-files:\n",
      "['../../Daten/Datensatz_H3D/DIM_2022/7 - DBScan/edited/554000_5798000.laz', '../../Daten/Datensatz_H3D/DIM_2022/7 - DBScan/edited/554000_5799000.laz', '../../Daten/Datensatz_H3D/DIM_2022/7 - DBScan/edited/554000_5800000.laz', '../../Daten/Datensatz_H3D/DIM_2022/7 - DBScan/edited/554000_5801000.laz', '../../Daten/Datensatz_H3D/DIM_2022/7 - DBScan/edited/555000_5798000.laz', '../../Daten/Datensatz_H3D/DIM_2022/7 - DBScan/edited/555000_5799000.laz', '../../Daten/Datensatz_H3D/DIM_2022/7 - DBScan/edited/555000_5800000.laz', '../../Daten/Datensatz_H3D/DIM_2022/7 - DBScan/edited/555000_5801000.laz', '../../Daten/Datensatz_H3D/DIM_2022/7 - DBScan/edited/556000_5798000.laz', '../../Daten/Datensatz_H3D/DIM_2022/7 - DBScan/edited/556000_5799000.laz', '../../Daten/Datensatz_H3D/DIM_2022/7 - DBScan/edited/556000_5800000.laz', '../../Daten/Datensatz_H3D/DIM_2022/7 - DBScan/edited/556000_5801000.laz']\n"
     ]
    }
   ],
   "source": [
    "# path where the data ist stored\n",
    "data_path = '../../Daten/Datensatz_H3D/'\n",
    "# sub-folder which includes different acquisition dates and types like 'DIM_2016', 'DIM_2019', 'DIM_2022', 'ALS2016', ...\n",
    "data = 'DIM_2022/7 - DBScan/edited'\n",
    "\n",
    "# save files that are in laz-format\n",
    "lst_files = []\n",
    "for file in os.listdir(data_path + data):\n",
    "    if file.endswith('.laz'):\n",
    "        lst_files.append(data_path + data + '/' + file)\n",
    "\n",
    "        \n",
    "lst_files = sorted(lst_files)\n",
    "print('Found', len(lst_files), 'laz-files:')\n",
    "print(lst_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cafb40-353a-48cf-bfcf-5f93be9f156f",
   "metadata": {},
   "source": [
    "Use function above to read the point cloud and convert it to pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea86763b-ae00-43d4-bd9e-c281e5b07513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../Daten/Datensatz_H3D/DIM_2022/7 - DBScan/edited/554000_5798000.laz'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define file we want to use\n",
    "las_path = lst_files[0]\n",
    "las_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "addeea3f-b308-4681-be0d-5b6fae19f3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>intensity</th>\n",
       "      <th>return_number</th>\n",
       "      <th>number_of_returns</th>\n",
       "      <th>scan_direction_flag</th>\n",
       "      <th>edge_of_flight_line</th>\n",
       "      <th>classification</th>\n",
       "      <th>synthetic</th>\n",
       "      <th>...</th>\n",
       "      <th>planarity</th>\n",
       "      <th>eigenentropy</th>\n",
       "      <th>curvature change</th>\n",
       "      <th>local_pointdensity</th>\n",
       "      <th>roughness</th>\n",
       "      <th>label</th>\n",
       "      <th>z_to_dem</th>\n",
       "      <th>inside_road</th>\n",
       "      <th>count_veg</th>\n",
       "      <th>count_ground</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>554866.15</td>\n",
       "      <td>5798487.56</td>\n",
       "      <td>70.56</td>\n",
       "      <td>8869</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>554864.20</td>\n",
       "      <td>5798487.63</td>\n",
       "      <td>70.45</td>\n",
       "      <td>8873</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.343253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>554877.16</td>\n",
       "      <td>5798492.81</td>\n",
       "      <td>70.61</td>\n",
       "      <td>9356</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.510372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>554864.20</td>\n",
       "      <td>5798487.79</td>\n",
       "      <td>70.47</td>\n",
       "      <td>8873</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.361733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>554869.83</td>\n",
       "      <td>5798491.05</td>\n",
       "      <td>74.13</td>\n",
       "      <td>17329</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.054098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631159</th>\n",
       "      <td>554330.37</td>\n",
       "      <td>5798588.29</td>\n",
       "      <td>69.24</td>\n",
       "      <td>7499</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.228618</td>\n",
       "      <td>-0.501297</td>\n",
       "      <td>0.431701</td>\n",
       "      <td>0.713115</td>\n",
       "      <td>0.674832</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.455299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631160</th>\n",
       "      <td>554326.79</td>\n",
       "      <td>5798588.75</td>\n",
       "      <td>69.24</td>\n",
       "      <td>7499</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274811</td>\n",
       "      <td>-3.273526</td>\n",
       "      <td>0.075397</td>\n",
       "      <td>1.068392</td>\n",
       "      <td>0.123233</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.453916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631161</th>\n",
       "      <td>554330.68</td>\n",
       "      <td>5798588.91</td>\n",
       "      <td>69.21</td>\n",
       "      <td>7499</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522878</td>\n",
       "      <td>-1.338616</td>\n",
       "      <td>0.041746</td>\n",
       "      <td>0.730131</td>\n",
       "      <td>0.963822</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.435219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631162</th>\n",
       "      <td>554324.51</td>\n",
       "      <td>5798587.84</td>\n",
       "      <td>69.27</td>\n",
       "      <td>10151</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.604568</td>\n",
       "      <td>-0.630222</td>\n",
       "      <td>0.383430</td>\n",
       "      <td>0.659132</td>\n",
       "      <td>1.499709</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.428519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631163</th>\n",
       "      <td>554330.83</td>\n",
       "      <td>5798588.60</td>\n",
       "      <td>69.24</td>\n",
       "      <td>7499</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433458</td>\n",
       "      <td>-2.014521</td>\n",
       "      <td>0.332797</td>\n",
       "      <td>0.710575</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.448757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5631164 rows Ã 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 X           Y      Z  intensity  return_number  \\\n",
       "0        554866.15  5798487.56  70.56       8869              1   \n",
       "1        554864.20  5798487.63  70.45       8873              1   \n",
       "2        554877.16  5798492.81  70.61       9356              1   \n",
       "3        554864.20  5798487.79  70.47       8873              1   \n",
       "4        554869.83  5798491.05  74.13      17329              1   \n",
       "...            ...         ...    ...        ...            ...   \n",
       "5631159  554330.37  5798588.29  69.24       7499              1   \n",
       "5631160  554326.79  5798588.75  69.24       7499              1   \n",
       "5631161  554330.68  5798588.91  69.21       7499              1   \n",
       "5631162  554324.51  5798587.84  69.27      10151              1   \n",
       "5631163  554330.83  5798588.60  69.24       7499              1   \n",
       "\n",
       "         number_of_returns  scan_direction_flag  edge_of_flight_line  \\\n",
       "0                        5                    0                    0   \n",
       "1                        2                    0                    0   \n",
       "2                        2                    0                    0   \n",
       "3                        2                    0                    0   \n",
       "4                        7                    0                    0   \n",
       "...                    ...                  ...                  ...   \n",
       "5631159                  4                    0                    0   \n",
       "5631160                  4                    0                    0   \n",
       "5631161                  5                    0                    0   \n",
       "5631162                  3                    0                    0   \n",
       "5631163                  5                    0                    0   \n",
       "\n",
       "         classification  synthetic  ...  planarity  eigenentropy  \\\n",
       "0                     6          0  ...        NaN           NaN   \n",
       "1                     6          0  ...        NaN           NaN   \n",
       "2                     6          0  ...        NaN           NaN   \n",
       "3                     6          0  ...        NaN           NaN   \n",
       "4                     6          0  ...        NaN           NaN   \n",
       "...                 ...        ...  ...        ...           ...   \n",
       "5631159               6          0  ...   1.228618     -0.501297   \n",
       "5631160               6          0  ...   0.274811     -3.273526   \n",
       "5631161               6          0  ...   0.522878     -1.338616   \n",
       "5631162               6          0  ...  -0.604568     -0.630222   \n",
       "5631163               6          0  ...  -0.433458     -2.014521   \n",
       "\n",
       "         curvature change  local_pointdensity  roughness  label  z_to_dem  \\\n",
       "0                     NaN                 NaN        NaN    NaN  0.507541   \n",
       "1                     NaN                 NaN        NaN    NaN  0.343253   \n",
       "2                     NaN                 NaN        NaN    NaN  0.510372   \n",
       "3                     NaN                 NaN        NaN    NaN  0.361733   \n",
       "4                     NaN                 NaN        NaN    NaN  4.054098   \n",
       "...                   ...                 ...        ...    ...       ...   \n",
       "5631159          0.431701            0.713115   0.674832    1.0  2.455299   \n",
       "5631160          0.075397            1.068392   0.123233    1.0  2.453916   \n",
       "5631161          0.041746            0.730131   0.963822    1.0  2.435219   \n",
       "5631162          0.383430            0.659132   1.499709    5.0  2.428519   \n",
       "5631163          0.332797            0.710575   0.999975    5.0  2.448757   \n",
       "\n",
       "         inside_road  count_veg  count_ground  \n",
       "0                0.0        NaN           NaN  \n",
       "1                0.0        NaN           NaN  \n",
       "2                0.0        NaN           NaN  \n",
       "3                0.0        NaN           NaN  \n",
       "4                0.0        NaN           NaN  \n",
       "...              ...        ...           ...  \n",
       "5631159          0.0       33.0          19.0  \n",
       "5631160          0.0       42.0           2.0  \n",
       "5631161          0.0       31.0          23.0  \n",
       "5631162          0.0       26.0          42.0  \n",
       "5631163          0.0       28.0          26.0  \n",
       "\n",
       "[5631164 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "df = import_las_to_Dataframe(las_path)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e0cb22-3999-4a6b-9f80-ae4a55ea2fa3",
   "metadata": {},
   "source": [
    "## Datapreparation\n",
    "Some of the features are not necessary/redudant. We will remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bb223c3-e0bf-48a1-be1c-4aa22971134e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>intensity</th>\n",
       "      <th>return_number</th>\n",
       "      <th>number_of_returns</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>554866.15</td>\n",
       "      <td>5798487.56</td>\n",
       "      <td>70.56</td>\n",
       "      <td>8869</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>554864.20</td>\n",
       "      <td>5798487.63</td>\n",
       "      <td>70.45</td>\n",
       "      <td>8873</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>554877.16</td>\n",
       "      <td>5798492.81</td>\n",
       "      <td>70.61</td>\n",
       "      <td>9356</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>554864.20</td>\n",
       "      <td>5798487.79</td>\n",
       "      <td>70.47</td>\n",
       "      <td>8873</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>554869.83</td>\n",
       "      <td>5798491.05</td>\n",
       "      <td>74.13</td>\n",
       "      <td>17329</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631159</th>\n",
       "      <td>554330.37</td>\n",
       "      <td>5798588.29</td>\n",
       "      <td>69.24</td>\n",
       "      <td>7499</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631160</th>\n",
       "      <td>554326.79</td>\n",
       "      <td>5798588.75</td>\n",
       "      <td>69.24</td>\n",
       "      <td>7499</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631161</th>\n",
       "      <td>554330.68</td>\n",
       "      <td>5798588.91</td>\n",
       "      <td>69.21</td>\n",
       "      <td>7499</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631162</th>\n",
       "      <td>554324.51</td>\n",
       "      <td>5798587.84</td>\n",
       "      <td>69.27</td>\n",
       "      <td>10151</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631163</th>\n",
       "      <td>554330.83</td>\n",
       "      <td>5798588.60</td>\n",
       "      <td>69.24</td>\n",
       "      <td>7499</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5600434 rows Ã 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 X           Y      Z  intensity  return_number  \\\n",
       "0        554866.15  5798487.56  70.56       8869              1   \n",
       "1        554864.20  5798487.63  70.45       8873              1   \n",
       "2        554877.16  5798492.81  70.61       9356              1   \n",
       "3        554864.20  5798487.79  70.47       8873              1   \n",
       "4        554869.83  5798491.05  74.13      17329              1   \n",
       "...            ...         ...    ...        ...            ...   \n",
       "5631159  554330.37  5798588.29  69.24       7499              1   \n",
       "5631160  554326.79  5798588.75  69.24       7499              1   \n",
       "5631161  554330.68  5798588.91  69.21       7499              1   \n",
       "5631162  554324.51  5798587.84  69.27      10151              1   \n",
       "5631163  554330.83  5798588.60  69.24       7499              1   \n",
       "\n",
       "         number_of_returns  classification  \n",
       "0                        5               6  \n",
       "1                        2               6  \n",
       "2                        2               6  \n",
       "3                        2               6  \n",
       "4                        7               6  \n",
       "...                    ...             ...  \n",
       "5631159                  4               6  \n",
       "5631160                  4               6  \n",
       "5631161                  5               6  \n",
       "5631162                  3               6  \n",
       "5631163                  5               6  \n",
       "\n",
       "[5600434 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[df['synthetic'] == 0]\n",
    "df = df.loc[:,['X','Y','Z','intensity','return_number', 'number_of_returns', 'classification']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a296ae2-d994-4a3b-a0ba-662e42aea2f5",
   "metadata": {},
   "source": [
    "## Point Cloud Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c57209-0c24-429d-8274-ec130e2f7b74",
   "metadata": {},
   "source": [
    "### Reduce area of the Pointcloud\n",
    "To reduce the number of points within the pointcloud, we will create a Bounding-Box to select a smaller areas of the pointcloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3c4206f-0775-435e-b1cb-15deb30ff363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check Results\n",
      "X min: 554000.0 X max: 554100.0\n",
      "Y min: 5798000.0 Y max: 5798100.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>intensity</th>\n",
       "      <th>return_number</th>\n",
       "      <th>number_of_returns</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>554055.63</td>\n",
       "      <td>5798086.94</td>\n",
       "      <td>66.41</td>\n",
       "      <td>9244</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>554055.63</td>\n",
       "      <td>5798086.40</td>\n",
       "      <td>66.49</td>\n",
       "      <td>9245</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>554055.86</td>\n",
       "      <td>5798083.58</td>\n",
       "      <td>66.56</td>\n",
       "      <td>8956</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>554054.66</td>\n",
       "      <td>5798084.38</td>\n",
       "      <td>66.78</td>\n",
       "      <td>9002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>554056.10</td>\n",
       "      <td>5798084.01</td>\n",
       "      <td>66.63</td>\n",
       "      <td>8956</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5621623</th>\n",
       "      <td>554090.44</td>\n",
       "      <td>5798068.78</td>\n",
       "      <td>65.94</td>\n",
       "      <td>8975</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5621624</th>\n",
       "      <td>554092.72</td>\n",
       "      <td>5798072.02</td>\n",
       "      <td>66.61</td>\n",
       "      <td>8777</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5622345</th>\n",
       "      <td>554016.48</td>\n",
       "      <td>5798054.33</td>\n",
       "      <td>64.78</td>\n",
       "      <td>9003</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5622346</th>\n",
       "      <td>554027.62</td>\n",
       "      <td>5798029.32</td>\n",
       "      <td>65.00</td>\n",
       "      <td>11818</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5622347</th>\n",
       "      <td>554016.71</td>\n",
       "      <td>5798053.91</td>\n",
       "      <td>64.77</td>\n",
       "      <td>8543</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63350 rows Ã 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 X           Y      Z  intensity  return_number  \\\n",
       "1961     554055.63  5798086.94  66.41       9244              1   \n",
       "1962     554055.63  5798086.40  66.49       9245              1   \n",
       "1963     554055.86  5798083.58  66.56       8956              1   \n",
       "1964     554054.66  5798084.38  66.78       9002              1   \n",
       "1965     554056.10  5798084.01  66.63       8956              1   \n",
       "...            ...         ...    ...        ...            ...   \n",
       "5621623  554090.44  5798068.78  65.94       8975              1   \n",
       "5621624  554092.72  5798072.02  66.61       8777              1   \n",
       "5622345  554016.48  5798054.33  64.78       9003              1   \n",
       "5622346  554027.62  5798029.32  65.00      11818              1   \n",
       "5622347  554016.71  5798053.91  64.77       8543              1   \n",
       "\n",
       "         number_of_returns  classification  \n",
       "1961                     5               6  \n",
       "1962                     4               6  \n",
       "1963                     2               6  \n",
       "1964                     2               6  \n",
       "1965                     6               6  \n",
       "...                    ...             ...  \n",
       "5621623                  3               6  \n",
       "5621624                  2               6  \n",
       "5622345                  3               2  \n",
       "5622346                  2               2  \n",
       "5622347                  2               2  \n",
       "\n",
       "[63350 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bounding Box\n",
    "bbox_x1 = df.X.min()\n",
    "bbox_y1 = df.Y.min()\n",
    "bbox_x2 = bbox_x1 + 100   # (df.X.max() - df.X.min()) / 1\n",
    "bbox_y2 = bbox_y1 + 100   # (df.Y.max() - df.Y.min()) / 1\n",
    "\n",
    "# Select Point inside of Bounding Box\n",
    "df_sub = df.loc[(df.X >= bbox_x1) & (df.Y >= bbox_y1) & (df.X <= bbox_x2) & (df.Y <= bbox_y2)]\n",
    "\n",
    "print('Check Results')\n",
    "print('X min:', df_sub.X.min(), 'X max:', df_sub.X.max())\n",
    "print('Y min:', df_sub.Y.min(), 'Y max:', df_sub.Y.max())\n",
    "\n",
    "# drop df to save memory\n",
    "del df, bbox_x1, bbox_y1, bbox_x2, bbox_y2\n",
    "\n",
    "df_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076b624a-58f9-4173-a8d4-410a16f7d2d7",
   "metadata": {},
   "source": [
    "## Set up PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e269fece-6a36-460f-b2c2-edf80977f89f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee3bfc0-83b9-4ac4-a244-94fa2d41094c",
   "metadata": {},
   "source": [
    "## Convert Dataframe to Numpy array\n",
    "Before we will go on with the processing we will convert the dataframe into a numpy array.<br>\n",
    "To speed up calculations and to save memory, we center the coordinates to the middle of the bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37f5369f-f34b-432c-bfc5-44a07bec32bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.63 ,  36.94 ,  -5.065],\n",
       "       [  5.63 ,  36.4  ,  -4.985],\n",
       "       [  5.86 ,  33.58 ,  -4.915],\n",
       "       ...,\n",
       "       [-33.52 ,   4.33 ,  -6.695],\n",
       "       [-22.38 , -20.68 ,  -6.475],\n",
       "       [-33.29 ,   3.91 ,  -6.705]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract x,y,z-columns from DataFrame and convert to NumPy array\n",
    "xyz_np = df_sub.loc[:,'X':'Z'].to_numpy()\n",
    "\n",
    "# center by center point of bounding box\n",
    "mini = np.min(xyz_np, axis=0)\n",
    "maxi = np.max(xyz_np, axis=0)\n",
    "xyz_np = xyz_np - np.expand_dims(0.5 * (maxi+mini), axis=0)\n",
    "xyz_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771d816a-7d7f-4f16-acb4-56d309243d94",
   "metadata": {},
   "source": [
    "## Convert DataFrame into Tensors\n",
    "First we will create a tensor wich contains the coordinates of the points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "219c94ae-2116-4f9a-90f7-dcea60818281",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of XYZ_Tensor: torch.Size([63350, 3])\n",
      "Number of dimensions of XYZ_Tensor: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  5.6300,  36.9400,  -5.0650],\n",
       "        [  5.6300,  36.4000,  -4.9850],\n",
       "        [  5.8600,  33.5800,  -4.9150],\n",
       "        ...,\n",
       "        [-33.5200,   4.3300,  -6.6950],\n",
       "        [-22.3800, -20.6800,  -6.4750],\n",
       "        [-33.2900,   3.9100,  -6.7050]], dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz = torch.from_numpy(xyz_np)\n",
    "print(f'Shape of XYZ_Tensor: {xyz.shape}')\n",
    "print(f'Number of dimensions of XYZ_Tensor: {len(xyz.shape)}')\n",
    "\n",
    "xyz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ec2a9c-416f-462a-96ba-8ff5df5868b3",
   "metadata": {},
   "source": [
    "Tensor must have three dimensions: <br>\n",
    "`(Batchsize x number of points x 3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3f341c6-7594-4351-906b-cc704b5e71e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 63350, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz = xyz.unsqueeze(0)\n",
    "xyz.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0296cd9-aaa0-425f-815b-f8a1d9fc015d",
   "metadata": {},
   "source": [
    "Next we create a tensor with the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d63a9a25-b504-4eb8-b627-e20aaea636fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of feature_Tensor: torch.Size([1, 63350, 3])\n",
      "Number of dimensions of feature_Tensor: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 9244,     1,     5],\n",
       "         [ 9245,     1,     4],\n",
       "         [ 8956,     1,     2],\n",
       "         ...,\n",
       "         [ 9003,     1,     3],\n",
       "         [11818,     1,     2],\n",
       "         [ 8543,     1,     2]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat = torch.from_numpy(df_sub.drop(['X','Y','Z','classification'], axis=1).to_numpy().astype(np.int32)).unsqueeze(0)\n",
    "print(f'Shape of feature_Tensor: {feat.shape}')\n",
    "print(f'Number of dimensions of feature_Tensor: {len(feat.shape)}')\n",
    "\n",
    "feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb8da27-81a4-49a7-9c92-8749c447103b",
   "metadata": {},
   "source": [
    "Create Tensor we the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9850daab-45fb-46a5-b598-4f8a53bc81e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 6, 6,  ..., 2, 2, 2], dtype=torch.uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.from_numpy(df_sub.classification.to_numpy())\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac13a87b-321d-4c9d-962b-e37e14acde78",
   "metadata": {},
   "source": [
    "Push our two tensors to the GPU to speed up the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "400e614b-1828-4db3-b00b-f4237839430e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor is coordinates ist now stored on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    xyz = xyz.to(device)\n",
    "    feat = feat.to(device)\n",
    "\n",
    "print(f'tensor is coordinates ist now stored on: {xyz.device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f15fb76f-4b9c-40df-b43d-136409ce7725",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_sub, xyz_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f62d4b-ec5f-4456-8319-114b623c9beb",
   "metadata": {},
   "source": [
    "## Sample and Group\n",
    "\n",
    "This part studies the sampling & grouping part of the Set Abstraction layer, which is then only followed by a multi-layer perceptron and max pooling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cba4254-8fee-4ccb-8eb0-f1139ce0a2f1",
   "metadata": {},
   "source": [
    "### Farthest point sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f66ebc-4444-4613-834d-7b7a7965dc59",
   "metadata": {},
   "source": [
    "First we need to create a function to execute the farthest point sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "746a7ea6-c945-4791-ad9f-460be5d03ae8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def farthest_point_sample(xyz, npoint):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        xyz: pointcloud data, [B, N, 3]\n",
    "        npoint: number of samples\n",
    "    Return:\n",
    "        centroids: sampled pointcloud index, [B, npoint]\n",
    "    \"\"\"\n",
    "    # get device\n",
    "    device = xyz.device\n",
    "    # Batchsize (B), number of points (N), num of dims (C)\n",
    "    B, N, C = xyz.shape\n",
    "    # initialze centroids with zeros\n",
    "    centroids = torch.zeros(B, npoint, dtype=torch.long).to(device)\n",
    "    # initialze distances with 1**10\n",
    "    distance = torch.ones(B, N, dtype=torch.float32).to(device) * 1e10\n",
    "    # initalize farthest point indices with random integar\n",
    "    farthest = torch.randint(0, N, (B,), dtype=torch.long).to(device)\n",
    "    # get indices of the batches\n",
    "    batch_indices = torch.arange(B, dtype=torch.long).to(device)\n",
    "    \n",
    "    # iterate throw number of points\n",
    "    for i in range(npoint):\n",
    "        centroids[:, i] = farthest\n",
    "        centroid = xyz[batch_indices, farthest, :].view(B, 1, 3)\n",
    "        dist = torch.sum((xyz - centroid) ** 2, -1, dtype=torch.float32)\n",
    "        mask = dist < distance\n",
    "        distance[mask] = dist[mask]\n",
    "        farthest = torch.max(distance, -1)[1]\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe051a7-7a3d-4dac-b494-436d0d30d166",
   "metadata": {},
   "source": [
    "Next we will check the results from our FPS-function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9646b6b-2886-425c-9d40-bb825863987c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the FPS-output: torch.Size([1, 1024])\n",
      "tensor([[24668, 54023, 17967,  ..., 46454, 56218, 45006]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "idx = farthest_point_sample(xyz, 1024)\n",
    "print(f'Shape of the FPS-output: {idx.shape}')\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc6f560-2753-4b0b-a467-b12cbdcad182",
   "metadata": {},
   "source": [
    "As we will notice, the functions results the indices of the sampled points.<br>\n",
    "We will create a function the gather the coordinates of the points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1256b9b2-6cda-4a0d-9a3f-43ad81884caf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def index_points(points, idx):\n",
    "    \"\"\"\n",
    "\n",
    "    Input:\n",
    "        points: input points data, [B, N, C]\n",
    "        idx: sample index data, [B, S]\n",
    "    Return:\n",
    "        new_points:, indexed points data, [B, S, C]\n",
    "    \"\"\"\n",
    "    device = points.device\n",
    "    B = points.shape[0]\n",
    "    view_shape = list(idx.shape)\n",
    "    view_shape[1:] = [1] * (len(view_shape) - 1)\n",
    "    repeat_shape = list(idx.shape)\n",
    "    repeat_shape[0] = 1\n",
    "    batch_indices = torch.arange(B, dtype=torch.long).to(device).view(view_shape).repeat(repeat_shape)\n",
    "    new_points = points[batch_indices, idx, :]\n",
    "    return new_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19311ab-350b-4914-aeaa-546b3cfc9ff5",
   "metadata": {},
   "source": [
    "Now we can use the function to get the coordinates of the sampeld points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d6c1a29-cb62-4a44-9955-2c152d8fa10f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled point tensor with shape torch.Size([1, 1024, 3])\n",
      "tensor([[[ 40.7800,  12.8000,  -6.0050],\n",
      "         [-49.7500, -49.6200,  -5.3550],\n",
      "         [-49.9700,  49.8000,  -6.8650],\n",
      "         ...,\n",
      "         [ 47.3200,  48.4600,  -4.6350],\n",
      "         [ 18.0600,  -2.4800,  -3.9550],\n",
      "         [ 13.4600, -17.5800,  -3.9050]]], device='cuda:0',\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "fps_points = index_points(xyz, idx)\n",
    "print(f'Sampled point tensor with shape {fps_points.shape}\\n{fps_points}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ed0e70-9fb6-4b69-b88c-0833aa456147",
   "metadata": {},
   "source": [
    "## Query fixed radius (ball) points\n",
    "\n",
    "For every sampled point, retrieve all points from the input within a given fixed radius. This is sometimes also referred to as a ball query. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a170dae-70ce-4fa1-ac6f-02defe85b491",
   "metadata": {},
   "source": [
    "First we will create a function to calculate the squared distance between the points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c5062cd-0ed1-40f4-842b-e2caf2795084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def square_distance(src, dst):\n",
    "    \"\"\"\n",
    "    Calculate Euclid distance between each two points.\n",
    "\n",
    "    src^T * dst = xn * xm + yn * ym + zn * zmï¼\n",
    "    sum(src^2, dim=-1) = xn*xn + yn*yn + zn*zn;\n",
    "    sum(dst^2, dim=-1) = xm*xm + ym*ym + zm*zm;\n",
    "    dist = (xn - xm)^2 + (yn - ym)^2 + (zn - zm)^2\n",
    "         = sum(src**2,dim=-1)+sum(dst**2,dim=-1)-2*src^T*dst\n",
    "\n",
    "    Input:\n",
    "        src: source points, [B, N, C]\n",
    "        dst: target points, [B, M, C]\n",
    "    Output:\n",
    "        dist: per-point square distance, [B, N, M]\n",
    "    \"\"\"\n",
    "    B, N, _ = src.shape\n",
    "    _, M, _ = dst.shape\n",
    "    dist = -2 * torch.matmul(src, dst.permute(0, 2, 1))\n",
    "    dist += torch.sum(src ** 2, -1).view(B, N, 1)\n",
    "    dist += torch.sum(dst ** 2, -1).view(B, 1, M)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c4d11a-577a-4de1-bee9-7483aa907a3c",
   "metadata": {},
   "source": [
    "Next we create a function to get the indices of our points inside the ball."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0cfeff2-96fa-4520-96f5-659353d65e90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_ball_point(radius, nsample, xyz, new_xyz):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        radius: local region radius\n",
    "        nsample: max sample number in local region\n",
    "        xyz: all points, [B, N, 3]\n",
    "        new_xyz: query points, [B, S, 3]\n",
    "    Return:\n",
    "        group_idx: grouped points index, [B, S, nsample]\n",
    "    \"\"\"\n",
    "    device = xyz.device\n",
    "    B, N, C = xyz.shape\n",
    "    _, S, _ = new_xyz.shape\n",
    "    group_idx = torch.arange(N, dtype=torch.long).to(device).view(1, 1, N).repeat([B, S, 1])\n",
    "    sqrdists = square_distance(new_xyz, xyz)\n",
    "    group_idx[sqrdists > radius ** 2] = N\n",
    "    group_idx = group_idx.sort(dim=-1)[0][:, :, :nsample]\n",
    "    group_first = group_idx[:, :, 0].view(B, S, 1).repeat([1, 1, nsample])\n",
    "    mask = group_idx == N\n",
    "    group_idx[mask] = group_first[mask]\n",
    "    return group_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90adb2b2-8f74-4670-b9f8-05040f883109",
   "metadata": {},
   "source": [
    "Check the results of our ball query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b94987b-0d96-4d1f-977b-08528c237962",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of our ball query has shape: torch.Size([1, 1024, 16])\n",
      "tensor([[[  470,   471,   472,  ..., 23849, 23898, 23899],\n",
      "         [  473,   496,   618,  ...,  1271,  1288,  1319],\n",
      "         [  398, 14042, 14071,  ..., 14409, 14456, 14488],\n",
      "         ...,\n",
      "         [  469, 31845, 31908,  ..., 32214, 32268, 32269],\n",
      "         [  483,   493,   499,  ...,   761,   788,   805],\n",
      "         [  486,   541,   543,  ...,   760,   770,   771]]])\n"
     ]
    }
   ],
   "source": [
    "# cause of memory limitation on the gpu we will do the calculation on the cpu\n",
    "xyz = xyz.to(torch.device('cpu'))\n",
    "fps_points = fps_points.to(torch.device('cpu'))\n",
    "\n",
    "idx_ball = query_ball_point(10, 16, xyz, fps_points)\n",
    "print(f'Result of our ball query has shape: {idx_ball.shape}\\n{idx_ball}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ab0df5-d76b-41a4-8f69-67a7863b4a35",
   "metadata": {},
   "source": [
    "Now we need to gather the points again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e7f0567-7033-4de5-961b-8215ffcda02f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor after FPS and grouping: torch.Size([1, 1024, 16, 3])\n"
     ]
    }
   ],
   "source": [
    "# put tensors back to gpu\n",
    "xyz = xyz.to(device)\n",
    "fps_points = fps_points.to(device)\n",
    "\n",
    "# gather points\n",
    "fps_group_points = index_points(xyz, idx_ball)\n",
    "print(f'Shape of tensor after FPS and grouping: {fps_group_points.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7db8c26-c607-4ecc-916f-f8c670ccf7dc",
   "metadata": {},
   "source": [
    "Now we have the neighboring points of every sampled point.\n",
    "\n",
    "### Zero-center every group \n",
    "Before each group can be processed by a small PointNet module (with an MLP and max pooling), every group must be zero-centered according to the sampling point it originates from. If we do not center the groups, each group is in its own coordinate space and the PointNet module could not learn shared features. Rather, it would try to learn features for all the different coordinate spaces, but would not succeed to generalize at all.group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9271ca1e-bb0e-40ba-8d9f-d55962099924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fps_group_points_centered = fps_group_points - fps_points.unsqueeze(2).repeat(1, 1, 16, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42eaf43-793e-4dce-8a0a-9ccbd0a7c1df",
   "metadata": {},
   "source": [
    "check the results on points 312"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aeb58729-5135-43a6-9468-fd9e941eb76c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the group:\n",
      "tensor([[48.8400, 45.8800, -5.9750],\n",
      "        [35.1800, 48.1800, -5.9650],\n",
      "        [38.5800, 44.1300, -5.9850],\n",
      "        [35.6600, 46.5500, -6.2250],\n",
      "        [35.7800, 47.0700, -6.4650]], device='cuda:0', dtype=torch.float64)\n",
      "\t...\n",
      "\n",
      "will be substracted by the smapled point:\n",
      "tensor([44.4900, 49.9300, -3.4650], device='cuda:0', dtype=torch.float64)\n",
      "\n",
      "wich results in\n",
      "tensor([[ 4.3500, -4.0500, -2.5100],\n",
      "        [-9.3100, -1.7500, -2.5000],\n",
      "        [-5.9100, -5.8000, -2.5200],\n",
      "        [-8.8300, -3.3800, -2.7600],\n",
      "        [-8.7100, -2.8600, -3.0000]], device='cuda:0', dtype=torch.float64)\n",
      "\t...\n"
     ]
    }
   ],
   "source": [
    "# look at group 312 before centering\n",
    "print(f'the group:\\n{fps_group_points[0, 312, 0:5, :]}\\n\\t...\\n\\nwill be substracted by the smapled point:\\n{fps_points[0, 312, :]}\\n\\nwich results in\\n{fps_group_points_centered[0, 312, 0:5, :]}\\n\\t...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c0868c-4cf8-4b2e-9d3c-d649d3a7a876",
   "metadata": {},
   "source": [
    "These zero-centered xyz-coordinates of the groups can now be fed into a PointNet module to extract geometric features for each group and by this for the sampling point. But PointNet++ also integrates further input features along with the xyz-coordinates before it applies a PointNet module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4930ed34-f3c2-45ed-86d7-c03a2dafb0eb",
   "metadata": {},
   "source": [
    "## Group features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf232524-83e3-46e3-b2dc-0f945f2dfd80",
   "metadata": {},
   "source": [
    "If there are further features per point as input besides the xyz-coordinates, then these features can be gathered with the `index_points()` function as well. <br>Feature could be input features like intensity, return number, etc., but are also features extracted from the previous set abstraction layer of the PointNet++ architecture.\n",
    "\n",
    "The get features we can use the index-tensor from the ball query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d8abfbf-99c0-431f-9a49-7087212c05d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 16, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_group = index_points(feat, idx_ball)\n",
    "feat_group.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83310a2f-5e5d-489e-97d8-9a807443fc0e",
   "metadata": {},
   "source": [
    "The feature groups do not need to be centered in any way. So, we are already finished.\n",
    "\n",
    "Both the zero-centered xyz-coordinates as well as the feature groups have the same tensor shapes with the exception of the last dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ea1559-ee97-4401-aff5-e5fd5bd97d22",
   "metadata": {},
   "source": [
    "Therefore, we can concatenate them into a single tensor by their last (-1) dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1395454-c136-4259-8641-b5f649e17cb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final output shape: torch.Size([1, 1024, 16, 6])\n"
     ]
    }
   ],
   "source": [
    "output = torch.cat((fps_group_points_centered, feat_group), 3)\n",
    "print(f'final output shape: {output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a0c0fe-5fc8-481c-9d0a-e1251686efec",
   "metadata": {},
   "source": [
    "This output tensor can now be used in a PointNet module for feature extraction. It does not matter that the geometric and other features are in the same tensor. Either the PointNet modules can learn something useful from this combination. And if not, then it will learn to ignore certain (feature) channels by setting the weights for this channel to 0. As PointNet applies a large number of filters, each filter can learn a different combination of features. But such an approach is the most flexible and most general approach to handling features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b21c7d8-aafb-4a2a-a07f-a1e4311076d1",
   "metadata": {},
   "source": [
    "### PointNet++ implementation of the Set Abstraction layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cad65c7-8b87-42de-9c3c-7492ce9d57ec",
   "metadata": {},
   "source": [
    "The first set abstraction layer might receive no input features, simply because the input data does not have any information besides the xyz-coordinates. Then, only the grouped points are the input to the PointNet module of the set abstraction layer. At the second set abstraction layer, there are always the features from the previous layer as additional input besides the coordinates. These features are provided by the variable called points (which is a confusing name and a better name would maybe be 'features').\n",
    "\n",
    "PointNet++ optionally does not include the grouped point xyz coordinates, but only continues with the grouped features. Then the concatenate part (as seen above) is not executed and only the grouped features are the output of the function to sample and group. This might be interesting for the second and higher set abstraction layer. But then, no further features are derived from the geometry in higher set abstraction layers. The default, however, is to use xyz-coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e7716e-66df-44e3-93e2-8b296a7563b0",
   "metadata": {},
   "source": [
    "In the following cell, an implementation of sample and group is given. You should recognize most of the parts (with the exception that there is also an option to use k nearest neighbors instead of a fixed radius ball query). \n",
    "\n",
    "As already mentioned above, the naming of the variables is sometimes a little confusing:\n",
    "\n",
    "- `npoint` is the number of points for farthest point sampling\n",
    "- `radius` is the radius of the fixed radius ball querys in each layer\n",
    "- `nsample` is the numbers of points in the fixed radius ball query\n",
    "- `xyz` input points\n",
    "- `points` feature tensor\n",
    "- `returnfps` is a boolean. If True it will return the `grouped_xyz` and the indices of the fps-points `fps_idx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cfd7647-0ef9-49b0-9952-f4c01f4c2ec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_and_group(npoint, radius, nsample, xyz, points, returnfps=False):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        npoint:\n",
    "        radius:\n",
    "        nsample:\n",
    "        xyz: input points position data, [B, N, 3]\n",
    "        points: input points data, [B, N, D]\n",
    "    Return:\n",
    "        new_xyz: sampled points position data, [B, npoint, nsample, 3]\n",
    "        new_points: sampled points data, [B, npoint, nsample, 3+D]\n",
    "    \"\"\"\n",
    "    # Batchsize (B), num of points (N), num of channels (C)\n",
    "    B, N, C = xyz.shape\n",
    "    # number of Sampling point\n",
    "    S = npoint\n",
    "    # get indices farthest point sampling\n",
    "    fps_idx = farthest_point_sample(xyz, npoint) # [B, npoint, C]\n",
    "    # gather points with indices\n",
    "    new_xyz = index_points(xyz, fps_idx)\n",
    "    # get indices fixed radius ball query\n",
    "    idx = query_ball_point(radius, nsample, xyz, new_xyz)\n",
    "    # gather coords of points with indices\n",
    "    grouped_xyz = index_points(xyz, idx) # [B, npoint, nsample, C]\n",
    "    # center the groups with the FPS-point\n",
    "    grouped_xyz_norm = grouped_xyz - new_xyz.view(B, S, 1, C)\n",
    "    \n",
    "    # add features if available\n",
    "    if points is not None:\n",
    "        grouped_points = index_points(points, idx)\n",
    "        new_points = torch.cat([grouped_xyz_norm, grouped_points], dim=-1) # [B, npoint, nsample, C+D]\n",
    "    else:\n",
    "        new_points = grouped_xyz_norm\n",
    "    if returnfps:\n",
    "        return new_xyz, new_points, grouped_xyz, fps_idx\n",
    "    else:\n",
    "        return new_xyz, new_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417b339f-0de8-41c4-928a-84f09ef3d93a",
   "metadata": {},
   "source": [
    "The function **sample_and_group()** implements all the above funcionality in a function and returns the sampled points, the grouped points with concatenated features, the indices from the ball query, and the grouped xyz-coordinates. Not all information is then further used in PointNet++.\n",
    "\n",
    "In the following, the function is called without input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da603c8c-348c-481a-b046-545d42c69834",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 16, 6])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz = xyz.to(torch.device('cpu'))\n",
    "feat = feat.to(torch.device('cpu'))\n",
    "\n",
    "new_xyz, new_points = sample_and_group(1024, 10, 16, xyz, feat)\n",
    "\n",
    "new_points.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346a81fc-d84c-4869-aeaf-8152663eafd5",
   "metadata": {},
   "source": [
    "## Set Abstraction (SA) layer\n",
    "\n",
    "In the following, a (simplified) implementation of the Set Abstraction layer is given as a TensorFlow custom layer. A custom layer is a class that is derived from the Keras base class Layer and can be used in a custom neural network model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbcf304-b473-4fa7-bbd7-d1bb6c0f811a",
   "metadata": {},
   "source": [
    "- The variable called `points` contains the feature tensor.\n",
    "- `npoint` is the number of points for farthest point sampling\n",
    "- `radius` is the radius of the fixed radius ball querys in each layer\n",
    "- `nsample` is the numbers of points in the fixed radius ball query\n",
    "- `in_channel` number of features\n",
    "- `mlp` contains a list with the number of filter for convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13bd12a2-9bdb-4d0d-aaab-74791ef3613e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45e1014f-76f8-4ece-a3b8-6175e6f87784",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNetSetAbstraction(nn.Module):\n",
    "    def __init__(self, npoint, radius, nsample, in_channel, mlp):\n",
    "        \n",
    "        super(PointNetSetAbstraction, self).__init__()\n",
    "        # number of points for FSP\n",
    "        self.npoint = npoint\n",
    "        # radois of the fixed ball query\n",
    "        self.radius = radius\n",
    "        # numbers of points in the fixed ball query\n",
    "        self.nsample = nsample\n",
    "        # empty list with convoltionals \n",
    "        self.mlp_convs = nn.ModuleList()\n",
    "        # empty list with batch normalisation\n",
    "        self.mlp_bns = nn.ModuleList()\n",
    "        last_channel = in_channel\n",
    "        # generate  MLPs\n",
    "        for out_channel in mlp:\n",
    "            # append convolution to list\n",
    "            self.mlp_convs.append(nn.Conv2d(last_channel, out_channel, 1))\n",
    "            # append batch normalisation to list\n",
    "            self.mlp_bns.append(nn.BatchNorm2d(out_channel))\n",
    "            last_channel = out_channel\n",
    "\n",
    "    def forward(self, xyz, points):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            xyz: input points position data, [B, C, N]\n",
    "            points: input features data, [B, D, N]\n",
    "        Return:\n",
    "            new_xyz: sampled points position data, [B, C, S]\n",
    "            new_points_concat: sample points feature data, [B, D', S]\n",
    "        \"\"\"\n",
    "        # xyz = xyz.permute(0, 2, 1)\n",
    "        # if points is not None:\n",
    "        #     points = points.permute(0, 2, 1)\n",
    "\n",
    "        new_xyz, new_points = sample_and_group(self.npoint, self.radius, self.nsample, xyz, points)\n",
    "        \n",
    "        # new_xyz: sampled points position data, [B, npoint, C]\n",
    "        # new_points: sampled points data, [B, npoint, nsample, C+D]\n",
    "        new_points = new_points.permute(0, 3, 2, 1).float() # [B, C+D, nsample, npoint]\n",
    "        for i, conv in enumerate(self.mlp_convs):\n",
    "            bn = self.mlp_bns[i]\n",
    "            new_points =  F.relu(bn(conv(new_points)))\n",
    "\n",
    "        new_points = torch.max(new_points, 2)[0].permute(0,2,1)\n",
    "        # new_xyz = new_xyz.permute(0, 2, 1)\n",
    "        return new_xyz, new_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a954d3b7-0112-4e8b-a794-4d3ed50777fa",
   "metadata": {},
   "source": [
    "As another option we could use **Mulit-Scale Grouping** inside of the Set Abstraction. <br>\n",
    "In this cas we will use differnt radii for the FPS algorithmn. <br>\n",
    "This is computionaly heavy - but sometimes its worth it.\n",
    "\n",
    "- The variable called `points` contains the feature tensor.\n",
    "- `npoint` is the number of points for farthest point sampling\n",
    "- `radius_list` is a list with the radius of the fixed radius ball querys in each layer\n",
    "- `nsample_list` is a list with the numbers of points in the fixed radius ball query\n",
    "- `in_channel` number of features\n",
    "- `mlp_list` contains a list with lists with the number of filter for convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2b265d7-9c97-40f5-92b3-5659cf19c362",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNetSetAbstractionMsg(nn.Module):\n",
    "    # PointNet Set Abstraction (SA) module with Multi-Scale Grouping (MSG)\n",
    "    def __init__(self, npoint, radius_list, nsample_list, in_channel, mlp_list):\n",
    "        \n",
    "        super(PointNetSetAbstractionMsg, self).__init__()\n",
    "        # number of points\n",
    "        self.npoint = npoint\n",
    "        \n",
    "        # list with radius for ball query\n",
    "        self.radius_list = radius_list\n",
    "        \n",
    "        # list with number of points of the ball query\n",
    "        self.nsample_list = nsample_list\n",
    "        \n",
    "        # empty list with convoltional blocks \n",
    "        self.conv_blocks = nn.ModuleList()\n",
    "        \n",
    "        # empty list with Batch-Normalisation blocks\n",
    "        self.bn_blocks = nn.ModuleList()\n",
    "        \n",
    "        # mlp_list contains the number of filters for convolution\n",
    "        for i in range(len(mlp_list)):\n",
    "            convs = nn.ModuleList()\n",
    "            bns = nn.ModuleList()\n",
    "            last_channel = in_channel + 3\n",
    "            for out_channel in mlp_list[i]:\n",
    "                convs.append(nn.Conv2d(last_channel, out_channel, 1))\n",
    "                bns.append(nn.BatchNorm2d(out_channel))\n",
    "                last_channel = out_channel\n",
    "            self.conv_blocks.append(convs)\n",
    "            self.bn_blocks.append(bns)\n",
    "\n",
    "    def forward(self, xyz, points):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            xyz: input points position data, [B, C, N]\n",
    "            points: input points data, [B, D, N]\n",
    "        Return:\n",
    "            new_xyz: sampled points position data, [B, C, S]\n",
    "            new_points_concat: sample points feature data, [B, D', S]\n",
    "        \"\"\"\n",
    "        # xyz = xyz.permute(0, 2, 1)\n",
    "        # if points is not None:\n",
    "        #     points = points.permute(0, 2, 1)\n",
    "\n",
    "        B, N, C = xyz.shape\n",
    "        S = self.npoint\n",
    "        new_xyz = index_points(xyz, farthest_point_sample(xyz, S))\n",
    "        new_points_list = []\n",
    "        for i, radius in enumerate(self.radius_list):\n",
    "            K = self.nsample_list[i]\n",
    "            group_idx = query_ball_point(radius, K, xyz, new_xyz)\n",
    "            grouped_xyz = index_points(xyz, group_idx)\n",
    "            grouped_xyz -= new_xyz.view(B, S, 1, C)\n",
    "            if points is not None:\n",
    "                grouped_points = index_points(points, group_idx)\n",
    "                grouped_points = torch.cat([grouped_points, grouped_xyz], dim=-1)\n",
    "            else:\n",
    "                grouped_points = grouped_xyz\n",
    "\n",
    "            grouped_points = grouped_points.permute(0, 3, 2, 1)  # [B, D, K, S]\n",
    "            for j in range(len(self.conv_blocks[i])):\n",
    "                conv = self.conv_blocks[i][j]\n",
    "                bn = self.bn_blocks[i][j]\n",
    "                grouped_points =  F.relu(bn(conv(grouped_points)))\n",
    "            new_points = torch.max(grouped_points, 2)[0]  # [B, D', S]\n",
    "            new_points_list.append(new_points)\n",
    "\n",
    "        new_xyz = new_xyz.permute(0, 2, 1)\n",
    "        new_points_concat = torch.cat(new_points_list, dim=1)\n",
    "        return new_xyz, new_points_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e09d3b-f1b8-4f00-ba90-6e1e7f6f1a3d",
   "metadata": {},
   "source": [
    "Let's see what it looks like, if we initalize our model end feed our data into the model.<br>\n",
    "In this step we don't use Multi-Sclae Grouping. The weights are initalized randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d5c4d39-3238-47fc-99da-227759844625",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 63350, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9f4fb08-b519-4a99-84e4-66ad42899f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of new_xyz:\n",
      "torch.Size([1, 1024, 3])\n",
      "new_xyz:\n",
      "tensor([[[ 17.4100, -17.9300,  -3.9150],\n",
      "         [-49.9700,  49.8000,  -6.8650],\n",
      "         [ 49.1400,  49.9000,  -6.5750],\n",
      "         ...,\n",
      "         [ 43.9600,  35.9100,  -4.9050],\n",
      "         [-48.9100,  12.2200,  -6.4050],\n",
      "         [ 22.8100, -25.5800,  -6.7750]]], dtype=torch.float64)\n",
      "\n",
      "shape of new_points:\n",
      " torch.Size([1, 1024, 64])\n",
      "new_points:\n",
      " tensor([[[1.4996, 1.0948, 1.5982,  ..., 0.8155, 1.0406, 1.5813],\n",
      "         [1.4724, 1.1278, 1.2414,  ..., 0.9598, 1.4609, 1.2604],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.9452, 1.4339, 0.0000],\n",
      "         ...,\n",
      "         [0.5805, 1.1876, 0.6565,  ..., 0.5039, 0.3675, 0.5328],\n",
      "         [0.0000, 1.1028, 0.2567,  ..., 0.9314, 1.3629, 0.3549],\n",
      "         [2.0140, 1.0989, 1.6969,  ..., 1.8418, 3.5543, 1.5028]]],\n",
      "       grad_fn=<PermuteBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = PointNetSetAbstraction(1024, 10, 16, 6, [32, 32, 64])\n",
    "new_xyz, new_points = model(xyz, feat.double())\n",
    "print(f'shape of new_xyz:\\n{new_xyz.shape}\\nnew_xyz:\\n{new_xyz}\\n\\nshape of new_points:\\n {new_points.shape}\\nnew_points:\\n {new_points}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6b7dd1-1853-40f3-919e-1e3493fcf286",
   "metadata": {},
   "source": [
    "## Feature Propagation\n",
    "After we defined the set abstraction (SA) layer, we need to propagate back.<br>\n",
    "To do so, we need to identify the nearest three points from the layer above and interpolate the feature with `inverse distance weights`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e24fa24-ed10-4a80-b5f7-f4d43b1c0ddd",
   "metadata": {},
   "source": [
    "### Distances to 3 nearest neighbors\n",
    "\n",
    "First we will calculate the distances to the three nearest points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f387d8a9-34ab-410a-900c-22286c702ffb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 5.7597,  7.3366,  7.3433],\n",
       "          [ 4.8837,  5.2625,  9.5816],\n",
       "          [ 1.1801, 13.4853, 15.4602],\n",
       "          ...,\n",
       "          [ 0.7362,  6.7118, 15.3636],\n",
       "          [ 5.3058,  9.3259,  9.7457],\n",
       "          [ 1.1630,  5.5428, 15.7274]]], dtype=torch.float64),\n",
       " tensor([[[734, 366, 114],\n",
       "          [114, 734, 908],\n",
       "          [114, 734, 619],\n",
       "          ...,\n",
       "          [459, 916, 972],\n",
       "          [878, 327, 897],\n",
       "          [459, 916,   4]]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate squared distances\n",
    "dists = square_distance(xyz, new_xyz)\n",
    "# sort the distances\n",
    "dists, idx = dists.sort(dim=-1)\n",
    "# just consider the first three points with the lowest distance\n",
    "dists, idx = dists[:, :, :3], idx[:, :, :3]  # [B, N, 3]\n",
    "dists, idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5684233f-035a-4a98-b4db-7c7352d9be3c",
   "metadata": {},
   "source": [
    "Now we can calculate the weights based on the inversed distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa22ae44-52b2-4628-8149-1f0121fc8545",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of weight matrix:\n",
      "torch.Size([1, 63350, 3])\n",
      "\n",
      "weight matrix:\n",
      "tensor([[[0.3892, 0.3055, 0.3053],\n",
      "         [0.4102, 0.3807, 0.2091],\n",
      "         [0.8592, 0.0752, 0.0656],\n",
      "         ...,\n",
      "         [0.8639, 0.0948, 0.0414],\n",
      "         [0.4732, 0.2692, 0.2576],\n",
      "         [0.7790, 0.1634, 0.0576]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "dist_recip = 1.0 / (dists + 1e-8)\n",
    "norm = torch.sum(dist_recip, dim=2, keepdim=True)\n",
    "weight = dist_recip / norm\n",
    "print(f'shape of weight matrix:\\n{weight.shape}\\n\\nweight matrix:\\n{weight}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8ec3e3-63d0-4482-aec7-40a203e76a0f",
   "metadata": {},
   "source": [
    "Now that we have the weights, we can iterpolate the features for the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aedacfb0-059d-4d42-9029-db45c9d3748c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of interpolated points:\n",
      "torch.Size([1, 63350, 64])\n",
      "\n",
      "interpolated points\n",
      "tensor([[[0.0000, 0.7999, 0.0000,  ..., 1.1108, 1.8103, 0.0000],\n",
      "         [0.0000, 0.8054, 0.0000,  ..., 1.1116, 1.8110, 0.0000],\n",
      "         [0.0000, 0.8122, 0.0000,  ..., 1.1130, 1.8115, 0.0000],\n",
      "         ...,\n",
      "         [1.4756, 1.1738, 1.5270,  ..., 0.9430, 1.3998, 1.4174],\n",
      "         [1.9385, 1.1456, 1.7143,  ..., 0.7773, 0.9430, 1.6848],\n",
      "         [1.4744, 1.1840, 1.5400,  ..., 0.9318, 1.3679, 1.4300]]],\n",
      "       dtype=torch.float64, grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "interpolated_points = torch.sum(index_points(new_points, idx) * weight.view(1, 63350, 3, 1), dim=2)\n",
    "print(f'shape of interpolated points:\\n{interpolated_points.shape}\\n\\ninterpolated points\\n{interpolated_points}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2efdcb-fc3b-4d7e-a826-bb50e2434eb8",
   "metadata": {},
   "source": [
    "As we can see we now have the features for every point of the input point size.\n",
    "\n",
    "Now let's put it all together into a single Layer which does all the steps above. <br>\n",
    "In adition the layer will add some MLP's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c701ad2e-5c72-4d34-a02f-739d164c9c56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PointNetFeaturePropagation(nn.Module):\n",
    "    def __init__(self, in_channel, mlp):\n",
    "        \n",
    "        super(PointNetFeaturePropagation, self).__init__()\n",
    "        \n",
    "        self.mlp_convs = nn.ModuleList()\n",
    "        self.mlp_bns = nn.ModuleList()\n",
    "        last_channel = in_channel\n",
    "        for out_channel in mlp:\n",
    "            self.mlp_convs.append(nn.Conv1d(last_channel, out_channel, 1))\n",
    "            self.mlp_bns.append(nn.BatchNorm1d(out_channel))\n",
    "            last_channel = out_channel\n",
    "\n",
    "    def forward(self, xyz1, xyz2, points1, points2):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            xyz1: input points position data, [B, N, C]\n",
    "            xyz2: sampled input points position data, [B, S, C]\n",
    "            points1: input points data, [B, N, D]\n",
    "            points2: input points data, [B, S, D]\n",
    "        Return:\n",
    "            new_points: upsampled points data, [B, D', N]\n",
    "        \"\"\"\n",
    "\n",
    "        B, N, C = xyz1.shape\n",
    "        _, S, _ = xyz2.shape\n",
    "\n",
    "        if S == 1:\n",
    "            interpolated_points = points2.repeat(1, N, 1)\n",
    "        else:\n",
    "            dists = square_distance(xyz1, xyz2)\n",
    "            dists, idx = dists.sort(dim=-1)\n",
    "            dists, idx = dists[:, :, :3], idx[:, :, :3]  # [B, N, 3]\n",
    "\n",
    "            dist_recip = 1.0 / (dists + 1e-8)\n",
    "            norm = torch.sum(dist_recip, dim=2, keepdim=True)\n",
    "            weight = dist_recip / norm\n",
    "            interpolated_points = torch.sum(index_points(points2, idx) * weight.view(B, N, 3, 1), dim=2)\n",
    "\n",
    "        if points1 is not None:\n",
    "            new_points = torch.cat([points1, interpolated_points], dim=-1)\n",
    "        else:\n",
    "            new_points = interpolated_points\n",
    "\n",
    "        new_points = new_points.permute(0, 2, 1)\n",
    "        for i, conv in enumerate(self.mlp_convs):\n",
    "            bn = self.mlp_bns[i]\n",
    "            new_points = F.relu(bn(conv(new_points.float())))\n",
    "        return new_points.permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5158e56-f76b-4a0c-bc7e-63e8453df451",
   "metadata": {},
   "source": [
    "Now we can check is the Feature propagation works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37a73978-55a9-4d2c-a224-0b34c3f7ca2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 63350, 128])\n"
     ]
    }
   ],
   "source": [
    "model_FP = PointNetFeaturePropagation(64+3, [64, 64, 128])\n",
    "points_FP = model_FP(xyz, new_xyz, feat, new_points)\n",
    "print(points_FP.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1b8202-68d2-405f-a672-015ee4de88c3",
   "metadata": {},
   "source": [
    "## Costum PointNet++ model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5f25158-7459-4283-971c-90dbe8b17199",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  2,  6, 20], dtype=torch.uint8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6733bd4c-494d-47a6-9dc8-061cd3bee592",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PointNet2(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        \n",
    "        super(PointNet2, self).__init__()\n",
    "        \n",
    "        # set abstraction layers\n",
    "        self.sa1 = PointNetSetAbstraction(npoint=8192, radius=1.0, nsample=16, in_channel=6 + 3, mlp=[64, 64, 128])\n",
    "        self.sa2 = PointNetSetAbstraction(npoint=4096, radius=5.0, nsample=64, in_channel=128 + 3, mlp=[128, 128, 256])\n",
    "        self.sa3 = PointNetSetAbstraction(npoint=2048, radius=15.0, nsample=64, in_channel=256 + 3, mlp=[128, 128, 256])\n",
    "        \n",
    "        # feature propagation\n",
    "        self.fp3 = PointNetFeaturePropagation(in_channel=512, mlp = [256, 256])\n",
    "        self.fp2 = PointNetFeaturePropagation(in_channel=384, mlp = [256, 256])\n",
    "        self.fp1 = PointNetFeaturePropagation(in_channel=256, mlp = [128, 64])\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(63350, 63350, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(63350)\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "        self.conv2 = nn.Conv1d(63350, num_classes, 1)\n",
    "    \n",
    "    def forward(self, xyz):\n",
    "        #xyz = xyz.permute(0, 2, 1)\n",
    "        l0_points = xyz\n",
    "        l0_xyz = xyz[:,:, 0:3]\n",
    "        \n",
    "        # set abstraction\n",
    "        l1_xyz, l1_points = self.sa1(l0_xyz, l0_points)\n",
    "        l2_xyz, l2_points = self.sa2(l1_xyz, l1_points)\n",
    "        l3_xyz, l3_points = self.sa3(l2_xyz, l2_points)\n",
    "        \n",
    "        # feature propagation\n",
    "        l2_points = self.fp3(l2_xyz, l3_xyz, l2_points, l3_points)\n",
    "        l1_points = self.fp2(l1_xyz, l2_xyz, l1_points, l2_points)\n",
    "        l0_points = self.fp1(l0_xyz, l1_xyz, None, l1_points)\n",
    "\n",
    "        x = self.drop1(F.relu(self.bn1(self.conv1(l0_points))))\n",
    "        x = self.conv2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x, l4_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312b10e2-71b6-4374-bc75-6f8336fcbad1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
